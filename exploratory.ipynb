{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = [16,10]\n",
    "\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('crime.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep only the UCR = 'Part One' type crimes, which are the most serious offenses. This will narrow it down from 67 different kinds of crimes down to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['UCR_PART'] == 'Part One']\n",
    "#drop unneccessary columns\n",
    "df = df.drop(['OFFENSE_CODE','UCR_PART','Location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OCCURRED_ON_DATE'] = pd.to_datetime(df['OCCURRED_ON_DATE']) #changing to datetime variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District, shooting, street, lat, and long columns all have nan values, lets take care of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SHOOTING.fillna('N', inplace = True) #most crimes dont involve shootings, so set it as N for 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DAY_OF_WEEK to an ordered category\n",
    "df.DAY_OF_WEEK = df['OCCURRED_ON_DATE'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 values in Lat/Long with Nan\n",
    "df.Lat.replace(-1, None, inplace=True)\n",
    "df.Long.replace(-1, None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to something easier to type\n",
    "rename = {'INCIDENT_NUMBER': 'id',\n",
    "         'OFFENSE_CODE_GROUP':'Group',\n",
    "         'OFFENSE_DESCRIPTION':'Description',\n",
    "         'DISTRICT':'District',\n",
    "         'REPORTING_AREA':'Area',\n",
    "         'SHOOTING':'Shooting',\n",
    "         'OCCURRED_ON_DATE':'Date',\n",
    "         'YEAR':'Year',\n",
    "         'MONTH':'Month',\n",
    "         'DAY_OF_WEEK':'Day',\n",
    "         'HOUR':'Hour',\n",
    "         'STREET':'Street'}\n",
    "df.rename(index=str, columns=rename, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really care too much about which street the crime occurs on. There are too many different streets in the entirerity of Boston, and this general location information is already somehwat encoded in other variables such as lat, lon, and district. We will not worry about filling out the nan values for that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything, since we aren't too concerend with modeling some behavior, and since we have more than 61 thousand entries, we can just drop all of the entries where there are null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Lat'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['District'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Street', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still end up with 58.8k fully filled entries for the crimes in Boston from June 14, 2015 to September 3, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot for crime types\n",
    "sns.catplot(y='Group',\n",
    "           kind='count',\n",
    "            height=8, \n",
    "            aspect=1.5,\n",
    "            order=df.Group.value_counts().index,\n",
    "           data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larceny seems to be the most common type of serious crime occuring in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, sharey=True)\n",
    "ax[0].plot(df.groupby('Hour').count()['id'], 'bo-', lw=2, alpha=0.7)\n",
    "ax[1].plot(df.groupby('Day').count()['id'], 'go-', lw=2, alpha=0.7)\n",
    "ax[2].plot(df.groupby('Month').count()['id'], 'ro-', lw=2, alpha=0.7)\n",
    "ax[0].set_xlabel('Hour of Day')\n",
    "ax[1].set_xlabel('Day of Week')\n",
    "ax[2].set_xlabel('Month of Year')\n",
    "ax[0].set_ylabel('Number of Rides')\n",
    "fig.suptitle('Number of Rides over Hour/Day/Month increments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the day, the lowest number of crimes occur at 5am, and gradually peak at near 6pm. During the week, the highest number of crimes occur on Friday. As for the month, the highest number of crimes peak during July. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the crimes with a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Lat',\n",
    "               y='Long',\n",
    "                hue='District',\n",
    "                alpha=0.01,\n",
    "               data=df)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest number of crimes seems to happen in districts A1 and D4, which are the most crowded downtown areas of Boston. There is also an unusually high concentration of crimes occuring in district D14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the history of the crimes happening throughout the day in Boston using folium heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df['Date'].dt.hour\n",
    "\n",
    "heat_df = df.sample(n= 5000) #take only random sample of 5k\n",
    "\n",
    "#extract required columns\n",
    "heat_df = heat_df[['Lat','Long', 'Hour']]\n",
    "\n",
    "#handle the columns as floats\n",
    "heat_df['Lat'] = df['Lat'].astype(float)\n",
    "heat_df['Long'] = df['Long'].astype(float)\n",
    "\n",
    "#create weight column, using the date\n",
    "heat_df['Weight'] = heat_df['Hour']\n",
    "heat_df['Weight'] = heat_df['Weight'].astype('float')\n",
    "heat_df = heat_df.dropna(axis= 0 , subset = ['Lat','Long', 'Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium.plugins as plugins\n",
    "boston_heatmap = folium.Map(location = [42.3125,-71.0875], tiles = 'Stamen Terrain', zoom_start =12)\n",
    "\n",
    "#list comprehension to make out list of lists\n",
    "heat_data = [[[row['Lat'], row['Long']]\n",
    "             for index, row in heat_df[heat_df['Weight']== i].iterrows()]\n",
    "                for i in range(0,24)] #0 to 24 for each hour of they day\n",
    "\n",
    "#plot it on the map\n",
    "hm = plugins.HeatMapWithTime(heat_data, auto_play = True, max_opacity = 0.9)\n",
    "hm.add_to(boston_heatmap)\n",
    "\n",
    "#display the map\n",
    "boston_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Larceny is the most common type of serious crime.\n",
    "- Serious crimes are most likely to occur in the afternoon and evening.\n",
    "- Serious crimes are most likely to occur on Friday and least likely to occur on Sunday.\n",
    "- Serious crimes are most likely to occur in the summer and early fall, and least likely to occur in the winter (with the exeption of January, which has a crime rate more similar to the summer).\n",
    "- Serious crimes are most common in the city center, especially districts A1 and D4.\n",
    "\n",
    "These observations only pertain to the \"serious\" crimes categorized under part one of the UCR codes. Part two and Part three may ascertain different results (obviously shoplifting is going to occur under different scenarios than larceny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Time Series\n",
    "\n",
    "**Let's look at the year 2017 (because we have the full year on record) and see how the crime is trending**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =  df[df['Year'] == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[:,'dayofyear'] = df2.loc[:,'Date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailycrimes= pd.DataFrame(df2.groupby(['District', 'dayofyear']).count()['id'])\n",
    "dailycrimes['unit'] = 1\n",
    "dailycrimes.reset_index(inplace =True)\n",
    "sns.tsplot(data=dailycrimes, time  = 'dayofyear', unit = 'unit', condition = 'District', value= 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to plot all of the different districts as a time series representing the number of crimes occuring over the course of 2017, its hard to visualize the trend, let's just sum them all together, and create one big crime time series for Boston. On the other hand, you could just single out one district, or merge a few districts to see their own trends as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df2.groupby('dayofyear').count()['id'], 'bo-', lw=2, alpha=0.7)\n",
    "plt.xlabel('Day of Year')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.title('Number of Rides over the Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =  df2.groupby('Date').count()['id']\n",
    "series = pd.DataFrame(({'day': count.index, 'count': count.values})).set_index('day')\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = series.resample('1D').sum()\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to see if we can identify some sort of seasonality in the plot above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ETS Graph (Error Trend Seasonality)\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result_ets = seasonal_decompose(series['count'],model='add')\n",
    "result_ets.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the over trend is hard to narrow down, there seems to be a strong weekly seasonality going on. \n",
    "Fit a polynomial of average weekly trend, subtrac it from the original dataset, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset, predicting Shootings being invovled with crimes in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Shooting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
